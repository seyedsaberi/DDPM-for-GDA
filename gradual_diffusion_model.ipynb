{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-11-09T08:19:03.996709Z",
     "iopub.status.busy": "2025-11-09T08:19:03.996299Z",
     "iopub.status.idle": "2025-11-09T08:19:33.156891Z",
     "shell.execute_reply": "2025-11-09T08:19:33.154073Z",
     "shell.execute_reply.started": "2025-11-09T08:19:03.996682Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !wget -O faces_dataset.tar.gz \"https://www.dropbox.com/scl/fi/7dv71y3nxrcdrpmwntr8e/faces_aligned_small_mirrored_co_aligned_cropped_cleaned.tar.gz?rlkey=h03r92h1mdr9yet2tkqosqq1k&dl=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T08:10:13.382550Z",
     "iopub.status.busy": "2025-11-09T08:10:13.382196Z",
     "iopub.status.idle": "2025-11-09T08:10:31.919051Z",
     "shell.execute_reply": "2025-11-09T08:10:31.917897Z",
     "shell.execute_reply.started": "2025-11-09T08:10:13.382516Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import tarfile\n",
    "\n",
    "# with tarfile.open(\"faces_dataset.tar.gz\", \"r:gz\") as tar:\n",
    "#     tar.extractall(\"faces_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T08:20:59.163007Z",
     "iopub.status.busy": "2025-11-09T08:20:59.162661Z",
     "iopub.status.idle": "2025-11-09T08:20:59.187366Z",
     "shell.execute_reply": "2025-11-09T08:20:59.186199Z",
     "shell.execute_reply.started": "2025-11-09T08:20:59.162984Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17673"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import os\n",
    "# file_names = os.listdir(\"/kaggle/working/faces_dataset/faces_aligned_small_mirrored_co_aligned_cropped_cleaned/M\")\n",
    "# len(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!git clone https://github.com/USERNAME/REPO.git\n",
    "sys.path.append('/kaggle/working/REPO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_lightning\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpl\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgda_functions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Config, set_seed_all, DiffusionTrainer, StreamDataModule\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from gda_functions import Config, set_seed_all, DiffusionTrainer, StreamDataModule, NoisedMixtureStream, pretrain_w3\n",
    "\n",
    "# Configure training for Kaggle 2*T4 GPUs\n",
    "cfg = Config()\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "n_gpus = torch.cuda.device_count() if use_gpu else 0\n",
    "strategy = \"ddp_notebook\" if (use_gpu and n_gpus >= 2) else \"auto\"\n",
    "\n",
    "\n",
    "# If no GPU, downgrade batch_size/steps/precision for faster CPU test runs\n",
    "if not use_gpu:\n",
    "    cfg.precision = \"32-true\"\n",
    "    cfg.steps = min(cfg.steps, 500)\n",
    "    cfg.batch_size = min(cfg.batch_size, 2048)\n",
    "\n",
    "set_seed_all(cfg.seed)\n",
    "\n",
    "# Step 1: Pre-train w3 to predict i from x_t\n",
    "print(\"=\"*60)\n",
    "print(\"STEP 1: Pre-training w3 to predict mixture index i\")\n",
    "print(\"=\"*60)\n",
    "device = torch.device(\"cuda\", 0) if use_gpu else torch.device(\"cpu\")\n",
    "pretrain_stream = NoisedMixtureStream(cfg, device=device)\n",
    "pretrained_w3 = pretrain_w3(cfg, pretrain_stream, pretrain_steps=500, lr=1e-2)\n",
    "print(f\"Pre-trained w3: {pretrained_w3.cpu()}\")\n",
    "print()\n",
    "\n",
    "# Step 2: Train diffusion model with pre-trained w3\n",
    "print(\"=\"*60)\n",
    "print(\"STEP 2: Training diffusion model with pre-trained w3\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# PyTorch Lightning DataModule automatically manages correct device and sharing stream params among workers\n",
    "datamodule = StreamDataModule(cfg)\n",
    "model = DiffusionTrainer(cfg, pretrained_w3=pretrained_w3)\n",
    "\n",
    "# Lightning config for multi-GPU (Kaggle 2xT4) or fallback\n",
    "trainer = pl.Trainer(\n",
    "    max_steps=cfg.steps,\n",
    "    accelerator=\"gpu\" if use_gpu else \"cpu\",\n",
    "    devices=n_gpus if use_gpu else None,\n",
    "    strategy=strategy,\n",
    "    precision=cfg.precision,\n",
    "    log_every_n_steps=cfg.log_every_n_steps,\n",
    "    enable_progress_bar=True,\n",
    "    enable_checkpointing=False,\n",
    "    gradient_clip_val=cfg.grad_clip_norm,\n",
    ")\n",
    "\n",
    "trainer.fit(model, datamodule=datamodule)\n",
    "\n",
    "# Extract and show learned parameters and data family params\n",
    "denoiser = model.model  # HalfSpaceDenoiser\n",
    "state = {k: v.detach().cpu() for k, v in denoiser.state_dict().items()}\n",
    "\n",
    "print(\"Learned parameters:\")\n",
    "print(\"w0:\", state.get(\"w0\"))\n",
    "print(\"w1:\", state.get(\"w1\"))\n",
    "if getattr(denoiser, \"use_extended\", False):\n",
    "    print(\"w2:\", state.get(\"w2\"))\n",
    "    print(\"w3:\", state.get(\"w3\"))\n",
    "print(\"b:\", state.get(\"b\"))\n",
    "\n",
    "# Read the actual training stream parameters if available\n",
    "if getattr(datamodule, \"stream\", None) is not None:\n",
    "    print(\"\\nData family parameters (training stream):\")\n",
    "    print(\"mu0:\", datamodule.stream.mu0.detach().cpu())\n",
    "    print(\"u:\", datamodule.stream.u.detach().cpu())\n",
    "else:\n",
    "    print(\"\\nData family parameters not available from datamodule.stream\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from gda_functions import NoisedMixtureStream\n",
    "\n",
    "# Create a stream with the same config and seed to get the same mu0 and u\n",
    "set_seed_all(cfg.seed)\n",
    "device = torch.device(\"cuda\", 0) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "stream = NoisedMixtureStream(cfg, device=device)\n",
    "\n",
    "mu0_np = stream.mu0.detach().cpu().numpy()\n",
    "u_np = stream.u.detach().cpu().numpy()\n",
    "\n",
    "print(f\"mu0 = {mu0_np}\")\n",
    "print(f\"u = {u_np}\")\n",
    "print(f\"||mu0|| = {np.linalg.norm(mu0_np):.4f}\")\n",
    "print(f\"||u|| = {np.linalg.norm(u_np):.4f}\")\n",
    "\n",
    "# If d=2, plot the vectors\n",
    "if len(mu0_np) == 2:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "    \n",
    "    # Plot origin\n",
    "    ax.scatter([0], [0], c='black', s=100, marker='o', label='Origin', zorder=5)\n",
    "    \n",
    "    # Plot mu0 vector\n",
    "    ax.quiver(0, 0, mu0_np[0], mu0_np[1], \n",
    "              angles='xy', scale_units='xy', scale=1, \n",
    "              color='blue', width=0.01, label=r'$\\mu_0$', zorder=4)\n",
    "    \n",
    "    # Plot u vector\n",
    "    ax.quiver(0, 0, u_np[0], u_np[1], \n",
    "              angles='xy', scale_units='xy', scale=1, \n",
    "              color='red', width=0.01, label=r'$u$', zorder=4)\n",
    "    \n",
    "    # Plot several mixture centers: mu_i = mu0 + i*u for i=0,...,N\n",
    "    N = cfg.N\n",
    "    for i in range(N + 1):\n",
    "        mu_i = mu0_np + i * u_np\n",
    "        ax.scatter(mu_i[0], mu_i[1], c='green', s=50, alpha=0.6, zorder=3)\n",
    "        if i == 0 or i == N:\n",
    "            ax.text(mu_i[0], mu_i[1], f'  i={i}', fontsize=9, va='bottom')\n",
    "    \n",
    "    ax.set_xlabel('Dimension 1', fontsize=12)\n",
    "    ax.set_ylabel('Dimension 2', fontsize=12)\n",
    "    ax.set_title(r'Data Family: $\\mu_i = \\mu_0 + i \\cdot u$ for $i=0,\\ldots,N$', fontsize=14)\n",
    "    ax.legend(fontsize=11)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.axis('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"\\nVisualization skipped (d={len(mu0_np)} != 2)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from gda_functions import sample_from_diffusion_with_i, sample_true_distribution\n",
    "\n",
    "# Choose which mixture index to generate\n",
    "target_i = 8  # You can change this to any value from 0 to cfg.N\n",
    "\n",
    "print(f\"Generating samples for mixture index i={target_i}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Generate samples from the trained diffusion model\n",
    "num_samples = 1000\n",
    "device = torch.device(\"cuda\", 0) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Move model to device\n",
    "denoiser_model = model.model.to(device)\n",
    "\n",
    "print(f\"Sampling {num_samples} samples from diffusion model...\")\n",
    "generated_samples = sample_from_diffusion_with_i(\n",
    "    denoiser_model, \n",
    "    cfg, \n",
    "    target_i, \n",
    "    pretrained_w3, \n",
    "    num_samples, \n",
    "    device\n",
    ")\n",
    "\n",
    "print(f\"Sampling {num_samples} samples from true distribution...\")\n",
    "true_samples = sample_true_distribution(stream, target_i, num_samples)\n",
    "\n",
    "# Convert to numpy for plotting\n",
    "gen_np = generated_samples.detach().cpu().numpy()\n",
    "true_np = true_samples.detach().cpu().numpy()\n",
    "\n",
    "print(f\"\\nGenerated samples mean: {gen_np.mean(axis=0)}\")\n",
    "print(f\"True samples mean: {true_np.mean(axis=0)}\")\n",
    "print(f\"\\nGenerated samples std: {gen_np.std(axis=0)}\")\n",
    "print(f\"True samples std: {true_np.std(axis=0)}\")\n",
    "\n",
    "# Compute mu_i for reference\n",
    "mu_i = (stream.mu0 + target_i * stream.u).detach().cpu().numpy()\n",
    "print(f\"\\nTrue mu_{target_i}: {mu_i}\")\n",
    "\n",
    "# If d=2, plot the distributions\n",
    "if cfg.d == 2:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    # Plot 1: Generated samples\n",
    "    axes[0].scatter(gen_np[:, 0], gen_np[:, 1], alpha=0.3, s=10, c='blue')\n",
    "    axes[0].scatter([mu_i[0], -mu_i[0]], [mu_i[1], -mu_i[1]], \n",
    "                   c='red', s=100, marker='x', linewidths=3, \n",
    "                   label=f'True centers (±μ_{target_i})')\n",
    "    axes[0].set_xlabel('Dimension 1', fontsize=12)\n",
    "    axes[0].set_ylabel('Dimension 2', fontsize=12)\n",
    "    axes[0].set_title(f'Generated Samples (i={target_i})', fontsize=14)\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].axis('equal')\n",
    "    \n",
    "    # Plot 2: True samples\n",
    "    axes[1].scatter(true_np[:, 0], true_np[:, 1], alpha=0.3, s=10, c='green')\n",
    "    axes[1].scatter([mu_i[0], -mu_i[0]], [mu_i[1], -mu_i[1]], \n",
    "                   c='red', s=100, marker='x', linewidths=3,\n",
    "                   label=f'True centers (±μ_{target_i})')\n",
    "    axes[1].set_xlabel('Dimension 1', fontsize=12)\n",
    "    axes[1].set_ylabel('Dimension 2', fontsize=12)\n",
    "    axes[1].set_title(f'True Samples (i={target_i})', fontsize=14)\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].axis('equal')\n",
    "    \n",
    "    # Plot 3: Overlay\n",
    "    axes[2].scatter(gen_np[:, 0], gen_np[:, 1], alpha=0.3, s=10, c='blue', label='Generated')\n",
    "    axes[2].scatter(true_np[:, 0], true_np[:, 1], alpha=0.3, s=10, c='green', label='True')\n",
    "    axes[2].scatter([mu_i[0], -mu_i[0]], [mu_i[1], -mu_i[1]], \n",
    "                   c='red', s=100, marker='x', linewidths=3,\n",
    "                   label=f'True centers (±μ_{target_i})')\n",
    "    axes[2].set_xlabel('Dimension 1', fontsize=12)\n",
    "    axes[2].set_ylabel('Dimension 2', fontsize=12)\n",
    "    axes[2].set_title(f'Overlay (i={target_i})', fontsize=14)\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    axes[2].axis('equal')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot histograms for each dimension\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    for dim in range(2):\n",
    "        axes[dim].hist(gen_np[:, dim], bins=50, alpha=0.5, label='Generated', color='blue', density=True)\n",
    "        axes[dim].hist(true_np[:, dim], bins=50, alpha=0.5, label='True', color='green', density=True)\n",
    "        axes[dim].axvline(mu_i[dim], color='red', linestyle='--', linewidth=2, label=f'μ_{target_i}[{dim}]')\n",
    "        axes[dim].axvline(-mu_i[dim], color='orange', linestyle='--', linewidth=2, label=f'-μ_{target_i}[{dim}]')\n",
    "        axes[dim].set_xlabel(f'Dimension {dim}', fontsize=12)\n",
    "        axes[dim].set_ylabel('Density', fontsize=12)\n",
    "        axes[dim].set_title(f'Distribution along Dimension {dim}', fontsize=14)\n",
    "        axes[dim].legend()\n",
    "        axes[dim].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"\\nVisualization skipped (d={cfg.d} != 2)\")\n",
    "    print(\"For high-dimensional data, consider using dimensionality reduction (PCA, t-SNE, etc.)\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
