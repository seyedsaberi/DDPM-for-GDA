{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !wget -O faces_dataset.tar.gz \"https://www.dropbox.com/scl/fi/7dv71y3nxrcdrpmwntr8e/faces_aligned_small_mirrored_co_aligned_cropped_cleaned.tar.gz?rlkey=h03r92h1mdr9yet2tkqosqq1k&dl=1\"","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","collapsed":true,"execution":{"iopub.execute_input":"2025-11-09T08:19:03.996709Z","iopub.status.busy":"2025-11-09T08:19:03.996299Z","iopub.status.idle":"2025-11-09T08:19:33.156891Z","shell.execute_reply":"2025-11-09T08:19:33.154073Z","shell.execute_reply.started":"2025-11-09T08:19:03.996682Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# import tarfile\n\n# with tarfile.open(\"faces_dataset.tar.gz\", \"r:gz\") as tar:\n#     tar.extractall(\"faces_dataset\")","metadata":{"execution":{"iopub.execute_input":"2025-11-09T08:10:13.382550Z","iopub.status.busy":"2025-11-09T08:10:13.382196Z","iopub.status.idle":"2025-11-09T08:10:31.919051Z","shell.execute_reply":"2025-11-09T08:10:31.917897Z","shell.execute_reply.started":"2025-11-09T08:10:13.382516Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import os\n# file_names = os.listdir(\"/kaggle/working/faces_dataset/faces_aligned_small_mirrored_co_aligned_cropped_cleaned/M\")\n# len(file_names)","metadata":{"execution":{"iopub.execute_input":"2025-11-09T08:20:59.163007Z","iopub.status.busy":"2025-11-09T08:20:59.162661Z","iopub.status.idle":"2025-11-09T08:20:59.187366Z","shell.execute_reply":"2025-11-09T08:20:59.186199Z","shell.execute_reply.started":"2025-11-09T08:20:59.162984Z"},"trusted":true},"outputs":[{"data":{"text/plain":["17673"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"execution_count":null},{"cell_type":"code","source":"import sys\n!git clone https://github.com/USERNAME/REPO.git\nsys.path.append('/kaggle/working/REPO')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport pytorch_lightning as pl\n\nfrom gda_functions import Config, set_seed_all, DiffusionTrainer, StreamDataModule\n\n# Configure training for Kaggle 2*T4 GPUs\ncfg = Config()\n\nuse_gpu = torch.cuda.is_available()\nn_gpus = torch.cuda.device_count() if use_gpu else 0\nstrategy = \"ddp_notebook\" if (use_gpu and n_gpus >= 2) else \"auto\"\n\n\n# If no GPU, downgrade batch_size/steps/precision for faster CPU test runs\nif not use_gpu:\n    cfg.precision = \"32-true\"\n    cfg.steps = min(cfg.steps, 500)\n    cfg.batch_size = min(cfg.batch_size, 2048)\n\nset_seed_all(cfg.seed)\n\n# PyTorch Lightning DataModule automatically manages correct device and sharing stream params among workers\ndatamodule = StreamDataModule(cfg)\nmodel = DiffusionTrainer(cfg)\n\n# Lightning config for multi-GPU (Kaggle 2xT4) or fallback\ntrainer = pl.Trainer(\n    max_steps=cfg.steps,\n    accelerator=\"gpu\" if use_gpu else \"cpu\",\n    devices=n_gpus if use_gpu else None,\n    strategy=strategy,\n    precision=cfg.precision,\n    log_every_n_steps=cfg.log_every_n_steps,\n    enable_progress_bar=True,\n    enable_checkpointing=False,\n    gradient_clip_val=cfg.grad_clip_norm,\n)\n\ntrainer.fit(model, datamodule=datamodule)\n\n# Extract and show learned parameters and data family params\ndenoiser = model.model  # HalfSpaceDenoiser\nstate = {k: v.detach().cpu() for k, v in denoiser.state_dict().items()}\n\nprint(\"Learned parameters:\")\nprint(\"w0:\", state.get(\"w0\"))\nprint(\"w1:\", state.get(\"w1\"))\nif getattr(denoiser, \"use_extended\", False):\n    print(\"w2:\", state.get(\"w2\"))\n    print(\"w3:\", state.get(\"w3\"))\nprint(\"b:\", state.get(\"b\"))\n\n# Read the actual training stream parameters if available\nif getattr(datamodule, \"stream\", None) is not None:\n    print(\"\\nData family parameters (training stream):\")\n    print(\"mu0:\", datamodule.stream.mu0.detach().cpu())\n    print(\"u:\", datamodule.stream.u.detach().cpu())\nelse:\n    print(\"\\nData family parameters not available from datamodule.stream\")\n","metadata":{},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'torch'","output_type":"error","traceback":["\u001b[31m---------------------------------------------------------------------------\u001b[39m","\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)","\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_lightning\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpl\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgda_functions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Config, set_seed_all, DiffusionTrainer, StreamDataModule\n","\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"]}],"execution_count":null}]}